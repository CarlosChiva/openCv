{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de las aplicaciones en las que se utilizan SVM en visión por computadora requieren una herramienta más poderosa que un simple clasificador lineal. Esto se debe al hecho de que en estas tareas los datos de entrenamiento rara vez se pueden separar mediante un hiperplano.\n",
    "\n",
    "El problema que presenta, por ejemplo, es la detección de rostros. Los datos de entrenamiento en este caso están compuestos por un conjunto de imágenes que son caras y otro conjunto de imágenes que no son caras ( cualquier otra cosa en el mundo excepto caras ). Estos datos de entrenamiento son demasiado complejos como para encontrar una representación de cada muestra ( vector de características ) que pueda hacer que todo el conjunto de caras sea linealmente separable del conjunto completo de no caras.\n",
    "\n",
    " El nuevo modelo debe incluir tanto el antiguo requisito de encontrar el hiperplano que proporcione el mayor margen como el nuevo de generalizar correctamente los datos de entrenamiento sin permitir demasiados errores de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process\n",
      "Finished training process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import random as rng\n",
    "\n",
    "NTRAINING_SAMPLES = 100 # Number of training samples per class\n",
    "FRAC_LINEAR_SEP = 0.9   # Fraction of samples which compose the linear separable part\n",
    "\n",
    "# Data for visual representation\n",
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "I = np.zeros((HEIGHT, WIDTH, 3), dtype=np.uint8)\n",
    "\n",
    "# --------------------- 1. Set up training data randomly ---------------------------------------\n",
    "\n",
    "trainData = np.empty((2*NTRAINING_SAMPLES, 2), dtype=np.float32)\n",
    "labels = np.empty((2*NTRAINING_SAMPLES, 1), dtype=np.int32)\n",
    "rng.seed(100) # Random value generation class\n",
    "\n",
    "# Set up the linearly separable part of the training data\n",
    "#Los datos de entrenamiento de este ejercicio están formados por un conjunto de puntos 2D etiquetados\n",
    "#que pertenecen a una de dos clases diferentes. Para hacer que el ejercicio sea más atractivo, \n",
    "#los datos de entrenamiento se generan aleatoriamente utilizando funciones de densidad de probabilidad uniforme (PDF)\n",
    "\n",
    "#Hemos dividido la generación de los datos de entrenamiento en dos partes principales.\n",
    "#En la primera parte generamos datos para ambas clases que son linealmente separables.\n",
    "\n",
    "nLinearSamples = int(FRAC_LINEAR_SEP * NTRAINING_SAMPLES)\n",
    "trainClass = trainData[0:nLinearSamples,:]\n",
    "# The x coordinate of the points is in [0, 0.4)\n",
    "c = trainClass[:,0:1]\n",
    "c[:] = np.random.uniform(0.0, 0.4 * WIDTH, c.shape)\n",
    "# The y coordinate of the points is in [0, 1)\n",
    "c = trainClass[:,1:2]\n",
    "c[:] = np.random.uniform(0.0, HEIGHT, c.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Generate random points for the class 2\n",
    "trainClass = trainData[2*NTRAINING_SAMPLES-nLinearSamples:2*NTRAINING_SAMPLES,:]\n",
    "# The x coordinate of the points is in [0.6, 1]\n",
    "c = trainClass[:,0:1]\n",
    "c[:] = np.random.uniform(0.6*WIDTH, WIDTH, c.shape)\n",
    "# The y coordinate of the points is in [0, 1)\n",
    "c = trainClass[:,1:2]\n",
    "c[:] = np.random.uniform(0.0, HEIGHT, c.shape)\n",
    "#------------------ Set up the non-linearly separable part of the training data ---------------\n",
    "\n",
    "#En la segunda parte creamos datos para ambas clases que no son separables linealmente, datos que se superponen.\n",
    "\n",
    "trainClass = trainData[nLinearSamples:2*NTRAINING_SAMPLES-nLinearSamples,:]\n",
    "\n",
    "# The x coordinate of the points is in [0.4, 0.6)\n",
    "c = trainClass[:,0:1]\n",
    "c[:] = np.random.uniform(0.4*WIDTH, 0.6*WIDTH, c.shape)\n",
    "\n",
    "# The y coordinate of the points is in [0, 1)\n",
    "c = trainClass[:,1:2]\n",
    "c[:] = np.random.uniform(0.0, HEIGHT, c.shape)\n",
    "\n",
    "#------------------------- Set up the labels for the classes ---------------------------------\n",
    "labels[0:NTRAINING_SAMPLES,:] = 1                   # Class 1\n",
    "labels[NTRAINING_SAMPLES:2*NTRAINING_SAMPLES,:] = 2 # Class 2\n",
    "\n",
    "#------------------------ 2. Set up the support vector machines parameters --------------------\n",
    "#Set up Model\n",
    "print('Starting training process')\n",
    "svm = cv.ml.SVM_create()\n",
    "svm.setType(cv.ml.SVM_C_SVC)\n",
    "svm.setC(0.1)\n",
    "svm.setKernel(cv.ml.SVM_LINEAR)\n",
    "svm.setTermCriteria((cv.TERM_CRITERIA_MAX_ITER, int(1e7), 1e-6))\n",
    "\n",
    "#------------------------ 3. Train the svm ----------------------------------------------------\n",
    "# Train model\n",
    "svm.train(trainData, cv.ml.ROW_SAMPLE, labels)\n",
    "print('Finished training process')\n",
    "\n",
    "#------------------------ 4. Show the decision regions ----------------------------------------\n",
    "green = (0,100,0)\n",
    "blue = (100,0,0)\n",
    "for i in range(I.shape[0]):\n",
    "    for j in range(I.shape[1]):\n",
    "        sampleMat = np.matrix([[j,i]], dtype=np.float32)\n",
    "        response = svm.predict(sampleMat)[1]\n",
    "        if response == 1:\n",
    "            I[i,j] = green\n",
    "        elif response == 2:\n",
    "            I[i,j] = blue\n",
    "#----------------------- 5. Show the training data --------------------------------------------\n",
    "thick = -1\n",
    "# Class 1\n",
    "for i in range(NTRAINING_SAMPLES):\n",
    "    px = trainData[i,0]\n",
    "    py = trainData[i,1]\n",
    "    cv.circle(I, (int(px), int(py)), 3, (0, 255, 0), thick)\n",
    "# Class 2\n",
    "for i in range(NTRAINING_SAMPLES, 2*NTRAINING_SAMPLES):\n",
    "    px = trainData[i,0]\n",
    "    py = trainData[i,1]\n",
    "    cv.circle(I, (int(px), int(py)), 3, (255, 0, 0), thick)\n",
    "#------------------------- 6. Show support vectors --------------------------------------------\n",
    "thick = 2\n",
    "sv = svm.getUncompressedSupportVectors()\n",
    "for i in range(sv.shape[0]):\n",
    "    cv.circle(I, (int(sv[i,0]), int(sv[i,1])), 6, (128, 128, 128), thick)\n",
    "cv.imwrite('resources/result1.png', I)                      # save the Image\n",
    "cv.imshow('SVM for Non-Linear Training Data', I) # show it to the user\n",
    "cv.waitKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
