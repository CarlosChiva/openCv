{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos una función del módulo calib3d, es decir, cv.findHomography() . Si pasamos el conjunto de puntos de ambas imágenes, encontrará la transformación de perspectiva de ese objeto. Luego podemos usar cv.perspectiveTransform() para encontrar el objeto. Se necesitan al menos cuatro puntos correctos para encontrar la transformación.\n",
    "\n",
    "Hemos visto que puede haber algunos errores posibles durante la comparación que pueden afectar el resultado. Para resolver este problema, el algoritmo utiliza RANSAC o LEAST_MEDIAN (que pueden decidirse mediante las banderas). Por lo tanto, las buenas coincidencias que proporcionan una estimación correcta se denominan valores internos y las restantes se denominan valores atípicos. cv.findHomography() devuelve una máscara que especifica los puntos internos y externos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "MIN_MATCH_COUNT = 10\n",
    "img1 = cv.imread('box.png', cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "img2 = cv.imread('box_in_scene.png', cv.IMREAD_GRAYSCALE) # trainImage\n",
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora establecemos la condición de que haya al menos 10 coincidencias (definidas por MIN_MATCH_COUNT) para encontrar el objeto. De lo contrario, simplemente muestre un mensaje que indique que no hay suficientes coincidencias.\n",
    "\n",
    "Si se encuentran suficientes coincidencias, extraemos las ubicaciones de los puntos clave coincidentes en ambas imágenes. Se pasan para encontrar la transformación de perspectiva. Una vez que obtenemos esta matriz de transformación de 3x3, la usamos para transformar las esquinas de queryImage en los puntos correspondientes en trainImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(good)>MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    h,w = img1.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv.perspectiveTransform(pts,M)\n",
    "    img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n",
    "else:\n",
    "    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "    matchesMask = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente dibujamos nuestros valores internos (si encontramos el objeto con éxito) o puntos clave coincidentes (si fallamos).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "plt.imshow(img3, 'gray'),plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
